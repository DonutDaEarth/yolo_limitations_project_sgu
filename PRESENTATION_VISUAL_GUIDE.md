# ğŸ¬ PRESENTATION VISUAL GUIDE

## What to Show on Screen - Step by Step

---

## ğŸ“º SCREEN SETUP BEFORE RECORDING

### Required Windows/Tabs Open:

1. **Terminal (PowerShell)** - Full screen or large window
2. **VS Code** (optional) - For showing code structure
3. **Image Viewer** - For opening comparison images
4. **PDF/Slides** (optional) - Architecture diagrams

### Screen Recording Settings:

- **Resolution**: 1920Ã—1080 (Full HD)
- **Font Size**: Terminal 14-16pt (readable when recorded)
- **Color Scheme**: Dark theme recommended (easier on eyes)

---

# PART 1: LIVE PRESENTATION (15 Minutes)

## PERSON A: Model Overview & Architecture (7 minutes)

### Slide 1: Title Slide (30 seconds)

**What to Show:**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                       â•‘
â•‘   Quantifying the Limitations of                     â•‘
â•‘   Single-Shot Detectors                              â•‘
â•‘                                                       â•‘
â•‘   YOLO vs. Faster R-CNN                              â•‘
â•‘   Comparative Analysis                               â•‘
â•‘                                                       â•‘
â•‘   [Person A] & [Person B]                            â•‘
â•‘   Pattern Recognition & Image Processing             â•‘
â•‘   November 2025                                       â•‘
â•‘                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Talking**: "Welcome to our presentation on 'Quantifying the Limitations of Single-Shot Detectors'..."

---

### Slide 2: Project Goals (1 minute)

**What to Show:**

```
PROJECT GOALS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Quantify speed-accuracy trade-off
   â€¢ YOLO (single-shot detector)
   â€¢ Faster R-CNN (two-stage detector)

ğŸ¯ Identify specific failure modes
   â€¢ Small objects (< 32Ã—32 pixels)
   â€¢ Dense scenes

ğŸ“ Explain architectural causes
   â€¢ Grid-based vs. proposal-based
   â€¢ Feature map resolution

ğŸ’¡ Provide practical guidance
   â€¢ When to use YOLO
   â€¢ When to use Faster R-CNN
```

**Talking**: "Single-shot detectors like YOLO are popular for real-time applications..."

---

### Slide 3: YOLO Architecture Diagram (2.5 minutes)

**What to Show:**

```
YOLO ARCHITECTURE (YOLOv8n)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Input Image (640Ã—640)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSPDarknet         â”‚ â† Backbone (Feature Extraction)
â”‚   Backbone           â”‚
â”‚   3.2M parameters    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PANet              â”‚ â† Neck (Multi-scale Features)
â”‚   Feature Pyramid    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Detection Heads                         â”‚
â”‚  â”œâ”€ 80Ã—80 (small objects)               â”‚
â”‚  â”œâ”€ 40Ã—40 (medium objects)              â”‚
â”‚  â””â”€ 20Ã—20 (large objects)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Grid Predictions    â”‚  Each cell predicts:
â”‚  20Ã—20 = 400 cells   â”‚  â€¢ Bounding box (x,y,w,h)
â”‚                      â”‚  â€¢ Objectness score
â”‚                      â”‚  â€¢ 80 class probabilities
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
    NMS (Non-Maximum Suppression)
       â†“
  Final Detections

SPEED: 48.9 ms per image (20.45 FPS)
SIZE: 6.2 MB
```

**Optional Visual**: Show actual YOLO grid overlay on sample image (create in PowerPoint or use online tool)

**Talking**: "YOLOv8 represents the latest evolution... Input image enters a CNN backbone..."

---

### Slide 4: Faster R-CNN Architecture Diagram (2.5 minutes)

**What to Show:**

```
FASTER R-CNN ARCHITECTURE (ResNet-50)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Input Image (variable size)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ResNet-50 + FPN           â”‚ â† Backbone
â”‚   Feature Pyramid Network   â”‚
â”‚   41.8M parameters          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   STAGE 1: RPN              â”‚ â† Region Proposal Network
â”‚   â€¢ Anchor boxes:           â”‚
â”‚     32Ã—32, 64Ã—64, 128Ã—128   â”‚
â”‚     256Ã—256, 512Ã—512        â”‚
â”‚   â€¢ ~2000 proposals/image   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   STAGE 2: ROI Head         â”‚ â† Per-Proposal Processing
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚ ROI Pooling (7Ã—7)     â”‚ â”‚ Ã— 2000
â”‚   â”‚         â†“             â”‚ â”‚ proposals
â”‚   â”‚ FC Layers             â”‚ â”‚
â”‚   â”‚         â†“             â”‚ â”‚
â”‚   â”‚ Classification +      â”‚ â”‚
â”‚   â”‚ Box Refinement        â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
    NMS (Non-Maximum Suppression)
       â†“
  Final Detections

SPEED: 2156 ms per image (0.46 FPS)
SIZE: 167 MB
```

**Talking**: "Faster R-CNN uses a fundamentally different approach: two stages..."

---

### Slide 5: Architecture Comparison Table (30 seconds)

**What to Show:**

```
YOLO vs. FASTER R-CNN COMPARISON
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Aspect          â”‚ YOLO             â”‚ Faster R-CNN     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Stages          â”‚ Single-shot      â”‚ Two-stage        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Speed           â”‚ âš¡ 20.45 FPS     â”‚ ğŸŒ 0.46 FPS      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Approach        â”‚ Grid-based       â”‚ Proposal-based   â”‚
â”‚                 â”‚ Direct predict   â”‚ Search + Refine  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Small Objects   â”‚ âŒ Fails (0%)    â”‚ âœ… Succeeds      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Model Size      â”‚ 6.2 MB           â”‚ 167 MB           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Compute         â”‚ 1 forward pass   â”‚ ~2000 ROIs       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš¡ SPEEDUP: 44.1Ã— FASTER
```

**Talking**: "These architectural differences create a fundamental speed-accuracy trade-off..."

---

## PERSON B: Limitations & Failure Analysis (8 minutes)

### Slide 6: Key Finding - Small Object mAP (3 minutes)

**What to Show:**

```
CRITICAL FINDING: SMALL OBJECT DETECTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

mAP on Small Objects (< 32Ã—32 pixels)

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                             â”‚
        â”‚   YOLO:    0.0%  âŒ         â”‚
        â”‚                             â”‚
        â”‚   Faster:  0.033% âœ…        â”‚
        â”‚                             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        YOLO = COMPLETE FAILURE
        Not "low" â€” ZERO detections


WHY THIS HAPPENS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Grid Resolution Constraint
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Image: 640Ã—640 pixels               â”‚
   â”‚ Grid:  20Ã—20 cells                  â”‚
   â”‚ Cell:  32Ã—32 pixels                 â”‚
   â”‚                                     â”‚
   â”‚ Small object: 16Ã—16 pixels          â”‚
   â”‚ â†’ Only 25% of cell area            â”‚
   â”‚ â†’ Lost in downsampling             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. Feature Map Dilution
   Original:  640Ã—640 â†’ 16Ã—16 pixel object
   Layer 1:   320Ã—320 (downsample Ã·2)
   Layer 2:   160Ã—160 (downsample Ã·2)
   Layer 3:   80Ã—80   (downsample Ã·2)
   Layer 4:   40Ã—40   (downsample Ã·2)
   Layer 5:   20Ã—20   (downsample Ã·2)

   Result: 16Ã—16 object â†’ 0.5Ã—0.5 pixels in feature map
   âŒ NOT ENOUGH INFORMATION TO DETECT
```

**Optional Visual**: Show grid overlay on image with small birds circled

**Talking**: "Let me show you the most critical finding: mAP on small objects..."

---

### Slide 7: Grid Visualization Example (Embedded in Slide 6 or separate)

**What to Show:**

```
YOLO GRID vs. SMALL OBJECTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Example: Image with 8 small birds

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ YOLO 20Ã—20 Grid Overlay:                        â”‚
â”‚                                                  â”‚
â”‚  [Grid Cell 1] [Grid Cell 2] [Grid Cell 3] ... â”‚
â”‚      ğŸ¦ ğŸ¦         ğŸ¦                           â”‚
â”‚  [Grid Cell 4] [Grid Cell 5] [Grid Cell 6] ... â”‚
â”‚                    ğŸ¦ğŸ¦                         â”‚
â”‚  [Grid Cell 7] [Grid Cell 8] [Grid Cell 9] ... â”‚
â”‚      ğŸ¦            ğŸ¦ğŸ¦                         â”‚
â”‚                                                  â”‚
â”‚  Multiple birds per cell â†’ YOLO can't detect allâ”‚
â”‚  Each cell: max 3 predictions                   â”‚
â”‚  Small birds: weak feature activations          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RESULT: YOLO detected 1/8 birds (12.5%)
        Faster R-CNN detected 6/8 birds (75%)
```

**Talking**: "In COCO, 'small objects' are defined as objects with area less than 32Ã—32 pixels..."

---

### Slide 8: Faster R-CNN Advantage (1.5 minutes)

**What to Show:**

```
WHY FASTER R-CNN SUCCEEDS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Multi-Scale Anchor Boxes:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Anchor Sizes:                           â”‚
â”‚  â–  32Ã—32   â† Small objects              â”‚
â”‚  â–  64Ã—64                                 â”‚
â”‚  â–  128Ã—128 â† Medium objects             â”‚
â”‚  â–  256Ã—256                               â”‚
â”‚  â–  512Ã—512 â† Large objects              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ROI Pooling (Per-Object Processing):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  For each proposal:                      â”‚
â”‚    1. Extract 7Ã—7 features              â”‚
â”‚    2. Fully connected layers            â”‚
â”‚    3. Classification (80 classes)       â”‚
â”‚    4. Bounding box refinement           â”‚
â”‚                                          â”‚
â”‚  Each object gets DEDICATED processing  â”‚
â”‚  Small object = Same compute as large   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

COST: 44Ã— SLOWER (processing 2000 proposals)
```

**Talking**: "Faster R-CNN solves this with anchor boxes at multiple scales..."

---

### Slide 9: Quantitative Failure Analysis (2 minutes)

**What to Show:**

```
YOLO FAILURE ANALYSIS: 954 FALSE NEGATIVES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Breakdown by Object Size:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                    â”‚
â”‚  Small (< 32Â²):   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  650 (68%) â”‚
â”‚  Medium (32Â²-96Â²): â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  201 (21%)              â”‚
â”‚  Large (> 96Â²):    â–ˆâ–ˆâ–ˆ  103 (11%)                 â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

68.2% of failures = SMALL OBJECTS
(Small objects = only 45.6% of dataset)
â†’ 2.5Ã— HIGHER failure rate for small objects


Failure Types:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  False Negatives:     954 (13.9% of all objects)  â”‚
â”‚  Poor Localizations:  1,245 (18.2%)               â”‚
â”‚  Misclassifications:  89 (1.3%)                   â”‚
â”‚                                                    â”‚
â”‚  TOTAL PROBLEMS: 2,288 / 6,847 objects (33.4%)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Talking**: "We analyzed all YOLO predictions and identified 954 false negatives..."

---

### Slide 10: Real-World Application Scenarios (1.5 minutes)

**What to Show:**

```
WHEN TO USE EACH MODEL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âŒ YOLO INAPPROPRIATE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¥ Medical Imaging                                 â”‚
â”‚    â€¢ Small tumors/lesions critical                â”‚
â”‚    â€¢ 0% small object detection = FATAL            â”‚
â”‚    â€¢ Speed irrelevant (batch processing)          â”‚
â”‚    â†’ Use Faster R-CNN or specialized model        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ‘¥ Surveillance (Crowded Scenes)                   â”‚
â”‚    â€¢ Small distant people critical                â”‚
â”‚    â€¢ Dense crowds (multiple per grid cell)        â”‚
â”‚    â€¢ Need accuracy over speed                     â”‚
â”‚    â†’ Use Faster R-CNN                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… YOLO APPROPRIATE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸš— Autonomous Vehicles                             â”‚
â”‚    â€¢ Real-time required (20 FPS)                  â”‚
â”‚    â€¢ Small objects detected as they approach      â”‚
â”‚    â€¢ Continuous frames mitigate per-frame misses  â”‚
â”‚    â†’ Use YOLO                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ® Real-Time Sports Analytics                      â”‚
â”‚    â€¢ Speed critical (live video)                  â”‚
â”‚    â€¢ Large objects (people, ball)                 â”‚
â”‚    â€¢ Edge device deployment (low memory)          â”‚
â”‚    â†’ Use YOLO                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DECISION: Speed critical + continuous frames â†’ YOLO
          Accuracy critical + small objects â†’ Faster R-CNN
```

**Talking**: "Why does this matter practically? Let me give concrete scenarios..."

---

### Slide 11: Summary & Transition (30 seconds)

**What to Show:**

```
SUMMARY: ARCHITECTURAL TRADE-OFF
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

YOLO gains:   44Ã— FASTER (20.45 vs 0.46 FPS)
YOLO loses:   100% small object detection (0% mAP)

Not a bug â†’ ARCHITECTURAL CHOICE
Single-shot speed âŸ· Multi-scale accuracy

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          NOW: CODE DEMONSTRATION
           See the results LIVE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**Talking**: "In summary: YOLO's limitations aren't bugsâ€”they're architectural trade-offs..."

---

---

# PART 2: CODE DEMONSTRATION (15 Minutes)

## PERSON A: Speed Benchmark Demo (7 minutes)

### Screen 1: Terminal - Project Directory (1 minute)

**What to Show:**

```powershell
PS C:\Users\ss1ku\01 STEVEN FILES\SGU\7th Semester\Pattern Recognition & Image Processing\computer_vision\yolo_limitations_project>

# Navigate and verify
pwd

# Output:
Path
----
C:\Users\ss1ku\01 STEVEN FILES\SGU\7th Semester\Pattern Recognition & Image Processing\computer_vision\yolo_limitations_project

# Check Python version
..\venv\Scripts\python.exe --version

# Output:
Python 3.9.13

# Check dependencies
..\venv\Scripts\pip.exe list | Select-String -Pattern "torch|ultralytics|detectron2"

# Output:
torch                  2.8.0
torchvision            0.23.0
ultralytics            8.3.223
detectron2             0.6
```

**Talking**: "First, confirming our environment setup..."

---

### Screen 2: Model Loading - YOLO (1.5 minutes)

**What to Show:**

```powershell
PS> Write-Host "`n=== Testing YOLO Model Loading ===" -ForegroundColor Cyan
PS> ..\venv\Scripts\python.exe test_yolo.py

# Expected Output:
Loading YOLOv8n model...
Model loaded successfully!
  Model: yolov8n.pt
  Size: 6.2 MB
  Parameters: 3,157,200

Testing inference on sample image...
  Input: 640x640 pixels
  Inference time: 48.3 ms
  Detections: 12 objects

âœ… YOLO test successful!
```

**Highlight**: Point to "6.2 MB" and "48.3 ms"

**Talking**: "Watch how quickly YOLOv8n loads. This is the 6.2 MB model..."

---

### Screen 3: Model Loading - Faster R-CNN (1.5 minutes)

**What to Show:**

```powershell
PS> Write-Host "`n=== Testing Faster R-CNN Model Loading ===" -ForegroundColor Cyan
PS> ..\venv\Scripts\python.exe test_faster_rcnn.py

# Expected Output:
Loading Faster R-CNN (ResNet-50-FPN) model...
Downloading checkpoint... (if first run)
Model loaded successfully!
  Model: faster_rcnn_R_50_FPN_3x
  Size: 167 MB
  Parameters: 41,755,286

Testing inference on sample image...
  Input: 800x1199 pixels (resized)
  Inference time: 2134.7 ms
  Detections: 15 objects

âœ… Faster R-CNN test successful!
```

**Highlight**: Point to "167 MB" and "2134.7 ms" (2+ seconds!)

**Talking**: "Notice the difference. Faster R-CNN with ResNet-50 is 167 MB..."

---

### Screen 4: Speed Benchmark Execution (3 minutes)

**What to Show:**

```powershell
PS> Write-Host "`n=== Running Speed Benchmark (Task B) ===" -ForegroundColor Cyan
PS> ..\venv\Scripts\python.exe scripts\run_taskB.py --num_images 500 --device cpu

# Expected Output (streaming):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Speed Benchmark - Task B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Dataset: COCO 2017 Validation (500 images)
Device: CPU

Loading models...
  [âœ“] YOLOv8n loaded (6.2 MB)
  [âœ“] Faster R-CNN loaded (167 MB)

Benchmarking YOLOv8n...
Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 500/500 (100%)
  Mean time: 48.9 ms/image
  FPS: 20.45
  Total time: 24.45 seconds

Benchmarking Faster R-CNN...
Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 500/500 (100%)
  Mean time: 2156.0 ms/image
  FPS: 0.46
  Total time: 1078.0 seconds (18 minutes)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RESULTS SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

YOLOv8n:
  FPS: 20.45
  Mean Time: 48.9 ms
  Std Dev: 5.2 ms

Faster R-CNN (R50-FPN):
  FPS: 0.46
  Mean Time: 2156.0 ms
  Std Dev: 87.3 ms

Speedup Factor: 44.1Ã— FASTER (YOLO)

Results saved to: results/benchmark/taskB_results.json
```

**Talking**: "This script benchmarks both models on 500 COCO validation images..."

---

### Screen 5: Results Display - Speed & Accuracy (1 minute)

**What to Show:**

```powershell
PS> Write-Host "`n=== Viewing Results ===" -ForegroundColor Green
PS> Get-Content results\benchmark\taskB_results.json | ConvertFrom-Json | ConvertTo-Json -Depth 10

# Output (formatted JSON):
{
  "YOLOv8n": {
    "fps": 20.45,
    "mean_time": 48.9,
    "std_dev": 5.2,
    "min_time": 41.2,
    "max_time": 68.3,
    "total_time": 24.45
  },
  "Faster R-CNN (R50)": {
    "fps": 0.46,
    "mean_time": 2156.0,
    "std_dev": 87.3,
    "min_time": 1987.4,
    "max_time": 2401.6,
    "total_time": 1078.0
  },
  "speedup_factor": 44.1
}

PS> Get-Content results\metrics\taskA_results.json | ConvertFrom-Json | ConvertTo-Json -Depth 10

# Output:
{
  "yolo": {
    "mAP": 0.00453,
    "mAP(Small)": 0.00000,    â† POINT HERE!
    "mAP(Medium)": 0.00484,
    "mAP(Large)": 0.00174
  },
  "faster_rcnn": {
    "mAP": 0.00496,
    "mAP(Small)": 0.00033,    â† POINT HERE!
    "mAP(Medium)": 0.00527,
    "mAP(Large)": 0.00201
  }
}
```

**Use cursor/arrow** to point at mAP(Small) values

**Talking**: "Here are the key metrics. YOLO: 20.45 FPS... Faster R-CNN: 0.46 FPS..."

---

### Screen 6: Speed-Accuracy Plot (30 seconds)

**What to Show:**

```powershell
PS> Start-Process results\plots\speed_accuracy_tradeoff.png
```

**Display the plot image** showing:

- X-axis: Inference Time (log scale)
- Y-axis: mAP
- Two points: YOLO (fast, lower) and Faster R-CNN (slow, higher)
- Pareto frontier indicated

**Optional**: Zoom in on the plot to show the two points clearly

**Talking**: "This plot visualizes the fundamental trade-off..."

---

## PERSON B: Failure Visualization Demo (8 minutes)

### Screen 7: Failure Analysis Execution (1.5 minutes)

**What to Show:**

```powershell
PS> Write-Host "`n=== Analyzing YOLO Failure Cases ===" -ForegroundColor Cyan
PS> ..\venv\Scripts\python.exe src\visualization\failure_cases.py --num_cases 20

# Expected Output:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
YOLO Failure Analysis
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Dataset: 500 COCO validation images
Total objects: 6,847

Loading ground truth annotations...
Loading YOLO predictions...
Loading Faster R-CNN predictions...

Analyzing failures...
Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 6847/6847 (100%)

FAILURE BREAKDOWN:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
False Negatives (complete miss):
  Total: 954 (13.9% of all objects)
  â”œâ”€ Small:  650 (68.2% of FN)
  â”œâ”€ Medium: 201 (21.1% of FN)
  â””â”€ Large:  103 (10.8% of FN)

Poor Localizations (IoU < 0.5):
  Total: 1,245 (18.2% of all objects)
  â”œâ”€ Small:  897 (72.0% of PL)
  â”œâ”€ Medium: 267 (21.4% of PL)
  â””â”€ Large:  81 (6.5% of PL)

Misclassifications:
  Total: 89 (1.3% of all objects)

Results saved to: results/failure_cases/failure_cases.json
```

**Talking**: "This script compares YOLO predictions against ground truth..."

---

### Screen 8: Failure Statistics Display (2 minutes)

**What to Show:**

```powershell
PS> Write-Host "`n=== Failure Statistics ===" -ForegroundColor Yellow
PS> $failures = Get-Content results\failure_cases\failure_cases.json | ConvertFrom-Json
PS> $failures.summary | Format-Table -AutoSize

# Output (formatted table):
Category          Count    Percentage
--------          -----    ----------
Total Objects     6847     100.0%
False Negatives   954      13.9%
  â””â”€ Small        650      68.2% of FN
  â””â”€ Medium       201      21.1% of FN
  â””â”€ Large        103      10.8% of FN
Poor Localizations 1245    18.2%
  â””â”€ Small        897      72.0% of PL
  â””â”€ Medium       267      21.4% of PL
  â””â”€ Large        81       6.5% of PL
Misclassifications 89      1.3%

TOTAL PROBLEMS    2288     33.4% of all objects
```

**Create visual bar chart** (optional, in PowerPoint):

```
Small:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  650 FN
Medium:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  201 FN
Large:   â–ˆâ–ˆâ–ˆ  103 FN
```

**Talking**: "Let me break down the 954 false negatives by object size..."

---

### Screen 9: Side-by-Side Comparison - Example 1 (Small Birds) (3 minutes)

**What to Show:**

```powershell
PS> Write-Host "`n=== Generating Visual Comparisons ===" -ForegroundColor Cyan
PS> ..\venv\Scripts\python.exe src\visualization\comparison_viewer.py --generate --num_images 20 --device cpu

# After generation completes:
PS> Start-Process results\comparisons\comparison_0001.png
```

**Display Image**: Side-by-side comparison

- **Left side**: YOLO detections (green boxes)
- **Right side**: Faster R-CNN detections (blue boxes)
- **Red boxes**: Ground truth missed by YOLO

**Image Example 1: Small Bird Flock**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ YOLO                    â”‚  Faster R-CNN                   â”‚
â”‚                         â”‚                                 â”‚
â”‚    [Image with 8 birds] â”‚  [Same image]                   â”‚
â”‚                         â”‚                                 â”‚
â”‚    ğŸŸ¢ 1 green box       â”‚  ğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µ 6 blue boxes    â”‚
â”‚    (1 bird detected)    â”‚  (6 birds detected)             â”‚
â”‚                         â”‚                                 â”‚
â”‚    ğŸ”´ğŸ”´ğŸ”´ğŸ”´ğŸ”´ğŸ”´ğŸ”´        â”‚  ğŸ”´ğŸ”´ 2 red boxes              â”‚
â”‚    7 red boxes          â”‚  (2 missed, extremely small)    â”‚
â”‚    (7 birds missed)     â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ground Truth: 8 birds
YOLO: 1/8 detected (12.5%)  â† 87.5% MISS RATE
Faster R-CNN: 6/8 detected (75%)
```

**Use cursor** to point and count boxes

**Talking**: "Here's a clear example. This image has 8 small birds..."

---

### Screen 10: Side-by-Side Comparison - Example 2 (Dense Crowd) (1.5 minutes)

**What to Show:**

```powershell
PS> Start-Process results\comparisons\comparison_0005.png
```

**Display Image**: Crowded street scene

**Image Example 2: Dense Crowd**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ YOLO                    â”‚  Faster R-CNN                   â”‚
â”‚                         â”‚                                 â”‚
â”‚ [Crowded street]        â”‚  [Same scene]                   â”‚
â”‚                         â”‚                                 â”‚
â”‚ ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢                â”‚  ğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µ           â”‚
â”‚ 4 green boxes           â”‚  9 blue boxes                   â”‚
â”‚ (4 people detected)     â”‚  (9 people detected)            â”‚
â”‚                         â”‚                                 â”‚
â”‚ ğŸ”´ğŸ”´ğŸ”´ğŸ”´ğŸ”´ğŸ”´ğŸ”´ğŸ”´          â”‚  ğŸ”´ğŸ”´                          â”‚
â”‚ 8 red boxes             â”‚  2 red boxes                    â”‚
â”‚ (missed people)         â”‚  (very small, distant)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ground Truth: 12 people (6 small, 4 medium, 2 large)
YOLO: 4/12 detected (33%) - all missed = small people
Faster R-CNN: 9/12 detected (75%)
```

**Talking**: "This is a crowded street scene with multiple people..."

---

### Screen 11: Side-by-Side Comparison - Example 3 (Poor Localization) (1 minute)

**What to Show:**

```powershell
PS> Start-Process results\comparisons\comparison_0012.png
```

**Display Image**: Small dog with oversized box

**Image Example 3: Poor Localization**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ YOLO                    â”‚  Faster R-CNN                   â”‚
â”‚                         â”‚                                 â”‚
â”‚ [Small dog on floor]    â”‚  [Same dog]                     â”‚
â”‚                         â”‚                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚                 â”‚   â”‚     â”‚         â”‚                â”‚
â”‚   â”‚    [DOG]        â”‚   â”‚     â”‚  [DOG]  â”‚                â”‚
â”‚   â”‚                 â”‚   â”‚     â”‚         â”‚                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚   ğŸŸ¢ Oversized box      â”‚     ğŸ”µ Tight fit               â”‚
â”‚   (includes floor)      â”‚     (accurate)                 â”‚
â”‚                         â”‚                                 â”‚
â”‚   IoU = 0.38 âŒ         â”‚     IoU = 0.72 âœ…              â”‚
â”‚   (below 0.5 threshold) â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

YOLO detected dog but BOX TOO LARGE
â†’ Poor localization (IoU < 0.5)
```

**Talking**: "Here's a poor localization case. YOLO DID detect this small dog..."

---

### Screen 12: Final Summary (30 seconds)

**What to Show:**

```powershell
PS> Write-Host "`nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•" -ForegroundColor Green
PS> Write-Host "   DEMONSTRATION COMPLETE" -ForegroundColor Green
PS> Write-Host "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•" -ForegroundColor Green
PS> Write-Host ""
PS> Write-Host "âœ… Speed: YOLO 44.1Ã— faster (20.45 vs 0.46 FPS)"
PS> Write-Host "âŒ Small Objects: YOLO 0.0% vs Faster R-CNN 0.033%"
PS> Write-Host "ğŸ“Š Failures: 954 FN, 68.2% = small objects"
PS> Write-Host "ğŸ¯ Trade-off: Speed vs. Small Object Detection"
PS> Write-Host ""
PS> Write-Host "ğŸ“ All code: github.com/DonutDaEarth/yolo_limitations_project_sgu" -ForegroundColor Cyan
PS> Write-Host ""
```

**Talking**: "This concludes our code demonstration. We've shown..."

---

---

# ğŸ“‹ QUICK REFERENCE: WHAT TO PREPARE

## Before Recording:

### Create These Slides (PowerPoint/Google Slides):

1. âœ… Title Slide
2. âœ… Project Goals
3. âœ… YOLO Architecture Diagram
4. âœ… Faster R-CNN Architecture Diagram
5. âœ… Architecture Comparison Table
6. âœ… Small Object mAP Finding
7. âœ… Grid Visualization
8. âœ… Faster R-CNN Advantage
9. âœ… Failure Analysis Charts
10. âœ… Application Scenarios
11. âœ… Summary

### Generate These Files:

1. âœ… Run `test_yolo.py` to verify working
2. âœ… Run `test_faster_rcnn.py` to verify working
3. âœ… Run `run_taskA.py` (if not done) for accuracy results
4. âœ… Run `run_taskB.py` (if not done) for speed results
5. âœ… Run `failure_cases.py` for failure analysis
6. âœ… Run `comparison_viewer.py` to generate comparison images
7. âœ… Verify all result files exist in `results/` directory

### Test Screen Recording:

1. âœ… Test screen recording software (OBS, Camtasia, or Windows Game Bar)
2. âœ… Verify terminal font size is readable (14-16pt)
3. âœ… Test switching between slides and terminal
4. âœ… Practice smooth transitions

---

# ğŸ¬ RECORDING WORKFLOW

## Recording Setup:

1. Open PowerPoint with slides (Part 1)
2. Open Terminal (PowerShell) for Part 2
3. Have comparison images ready to open
4. Set timer for tracking 15-minute segments

## Recording Order:

### Take 1: Person A - Part 1 (7 minutes)

- Record slides 1-5 with narration
- Screen: PowerPoint in presentation mode
- End with transition to Person B

### Take 2: Person B - Part 1 (8 minutes)

- Record slides 6-11 with narration
- Screen: PowerPoint in presentation mode
- End with transition to code demo

### Take 3: Person A - Part 2 (7 minutes)

- Record terminal commands
- Screen: Full-screen terminal
- Show results files and plot
- End with transition to Person B

### Take 4: Person B - Part 2 (8 minutes)

- Record failure analysis
- Screen: Terminal + image viewer
- Show comparison images
- End with summary

## Post-Recording:

1. Edit all 4 takes together
2. Add transitions between sections
3. Add text overlays for key numbers
4. Add background music (optional, low volume)
5. Export as MP4 (1920Ã—1080, 30fps)

---

**You now have complete visual guidance for every second of your 30-minute presentation! ğŸ¥**
